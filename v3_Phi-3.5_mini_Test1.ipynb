{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a5ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Pyg\\Projects\\semi\\yuzyproject-aimodels\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì‹¤í–‰ í™˜ê²½: CUDA (GPU)\n"
     ]
    }
   ],
   "source": [
    "# [Cell 1] ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# ì„¤ì •ê°’\n",
    "INPUT_FILE = \"project_full_context.txt\"\n",
    "OUTPUT_JSON = \"project_flows.json\"\n",
    "\n",
    "# GPU í™•ì¸\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸš€ ì‹¤í–‰ í™˜ê²½: {'CUDA (GPU)' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dbf3691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘... (microsoft/Phi-3.5-mini-instruct)\n",
      "   -> 4ë¹„íŠ¸ ì–‘ìí™”ë¡œ ë¡œë”©í•˜ì—¬ ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# [Cell 2] ì´ˆê³ ì† ê²½ëŸ‰ ëª¨ë¸ ë¡œë”© (4ë¹„íŠ¸ ìµœì í™”)\n",
    "\n",
    "# ======================================================\n",
    "# [ëª¨ë¸ ì„ íƒ] ì•„ë˜ ë³€ìˆ˜ ì¤‘ í•˜ë‚˜ë§Œ ì£¼ì„(#)ì„ í’€ì–´ì„œ ì‚¬ìš©.\n",
    "# ======================================================\n",
    "\n",
    "# 1. [ì¶”ì²œ] Microsoft Phi-3.5 (3.8B) - 4ë¹„íŠ¸ ì‹œ ì†ë„ ë¹ ë¥´ê³  ì§€ëŠ¥ ìµœê°•\n",
    "MODEL_ID = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "\n",
    "# 2. [ë¹„ìƒìš©] TinyLlama (1.1B) - ì„±ëŠ¥ì€ ë‚®ì§€ë§Œ ì••ë„ì ì¸ ì†ë„\n",
    "# MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# 3. [ì½”ë“œíŠ¹í™”] StarCoder2 (3B) - ìˆœìˆ˜ ì½”ë”©ìš© (ì±„íŒ… ëŠ¥ë ¥ì€ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ)\n",
    "# MODEL_ID = \"bigcode/starcoder2-3b\"\n",
    "\n",
    "# 4. [ì•ˆì •ì„±] Stable Code (3B) - Stability AIì˜ ì½”ë”© ëª¨ë¸\n",
    "# MODEL_ID = \"stabilityai/stable-code-3b\"\n",
    "\n",
    "# ======================================================\n",
    "\n",
    "# 4ë¹„íŠ¸ ì–‘ìí™” ì„¤ì • (ì†ë„ í–¥ìƒ ë° ë©”ëª¨ë¦¬ ì ˆì•½ í•µì‹¬)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(f\"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘... ({MODEL_ID})\")\n",
    "    print(\"   -> 4ë¹„íŠ¸ ì–‘ìí™”ë¡œ ë¡œë”©í•˜ì—¬ ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config, # 4ë¹„íŠ¸ ì ìš©\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        attn_implementation=\"eager\" # ì—ëŸ¬ ë°©ì§€ìš©\n",
    "    )\n",
    "    \n",
    "    # íŒ¨ë”© í† í° ì„¤ì • (ì—ëŸ¬ ë°©ì§€)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38adbcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê³„ì¸µí˜• ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# [Cell 3] í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € (ê³„ì¸µí˜• íŠ¸ë¦¬ êµ¬ì¡° ì „ìš©)\n",
    "\n",
    "# ìˆ˜ì •ëœ SYSTEM_PROMPT (DB ë° ë¯¸ë“¤ì›¨ì–´ ì¶”ì  ê°•í™”)\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a 'Backend Code Analyst'.\n",
    "Your task is to generate a **Precise Call Graph** based ONLY on the provided code.\n",
    "\n",
    "### CRITICAL RULES (DO NOT HALLUCINATE)\n",
    "1. **Identify Database Driver**: Check `package.json` or imports. Is it `mongoose`, `mysql2`, or `pg`?\n",
    "   - If `mongoose` is used, DO NOT output SQL queries like `SELECT *`. Use Mongoose methods like `find()`, `save()`.\n",
    "2. **Trace Middleware**: If a router has `isAuth` or `validate`, you MUST include them in `children`.\n",
    "3. **Deep Trace**: Go from Router -> Middleware -> Controller -> Service/Data -> DB Library.\n",
    "\n",
    "### JSON OUTPUT FORMAT\n",
    "{\n",
    "  \"api\": [\n",
    "    {\n",
    "      \"category\": \"auth\",\n",
    "      \"categoryName\": \"Auth Feature\",\n",
    "      \"endpoints\": [\n",
    "        {\n",
    "          \"method\": \"POST\",\n",
    "          \"url\": \"/auth/signup\",\n",
    "          \"function\": \"signup\",\n",
    "          \"file\": \"controller/auth.mjs\",\n",
    "          \"description\": \"User Signup\",\n",
    "          \"children\": [\n",
    "            {\n",
    "              \"function\": \"validateSignup\",\n",
    "              \"file\": \"router/auth.mjs\",\n",
    "              \"description\": \"Validation Chain\",\n",
    "              \"children\": []\n",
    "            },\n",
    "            {\n",
    "              \"function\": \"bcrypt.hashSync\",\n",
    "              \"file\": \"controller/auth.mjs\",\n",
    "              \"description\": \"Password Hashing\",\n",
    "              \"children\": []\n",
    "            },\n",
    "            {\n",
    "              \"function\": \"createUser\",\n",
    "              \"file\": \"data/auth.mjs\",\n",
    "              \"description\": \"Save to DB\",\n",
    "              \"children\": [\n",
    "                {\n",
    "                   \"function\": \"User.save()\",\n",
    "                   \"file\": \"mongoose\",\n",
    "                   \"description\": \"MongoDB Insert\",\n",
    "                   \"children\": []\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… ê³„ì¸µí˜• ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0acc373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ 'project_full_context.txt' ì½ëŠ” ì¤‘...\n",
      "ğŸ§  Phi-3.5-mini-instruct ëª¨ë¸ì´ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JSON ìƒì„± ì„±ê³µ! -> project_flows.json\n"
     ]
    }
   ],
   "source": [
    "# [Cell 4] ì½”ë“œ ë¶„ì„ ë° JSON ìƒì„± (ê²½ëŸ‰ ëª¨ë¸ ìµœì í™”)\n",
    "\n",
    "def extract_json(text):\n",
    "    text = re.sub(r\"^```(json)?\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "    text = re.sub(r\"```$\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "    start = text.find('{')\n",
    "    end = text.rfind('}')\n",
    "    if start == -1 or end == -1: return \"{}\"\n",
    "    return text[start:end+1]\n",
    "\n",
    "def run_full_scan():\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"âŒ '{INPUT_FILE}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ“‚ '{INPUT_FILE}' ì½ëŠ” ì¤‘...\")\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        full_code = f.read()\n",
    "        \n",
    "    # ê²½ëŸ‰ ëª¨ë¸ì€ ì…ë ¥ì´ ë„ˆë¬´ ê¸¸ë©´ í˜ë“¤ì–´í•  ìˆ˜ ìˆì–´ 30,000ìë¡œ ì œí•œ (í•„ìš”ì‹œ ì¡°ì ˆ)\n",
    "    code_context = full_code[:50000] \n",
    "\n",
    "    # [ì¤‘ìš”] ê²½ëŸ‰ ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸ (ëª…í™•í•˜ê³  ì§§ê²Œ ì§€ì‹œ)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze this code and return JSON ONLY:\\n\\n{code_context}\"}\n",
    "    ]\n",
    "\n",
    "    # ì±„íŒ… í…œí”Œë¦¿ ì ìš© (ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ì•ˆì „ì¥ì¹˜ ì¶”ê°€)\n",
    "    try:\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "    except Exception:\n",
    "        # í…œí”Œë¦¿ ì§€ì› ì•ˆ í•˜ëŠ” ëª¨ë¸(StarCoder ë“±)ì„ ìœ„í•œ ì˜ˆì™¸ì²˜ë¦¬\n",
    "        text = f\"{SYSTEM_PROMPT}\\n\\nUser: Analyze this code:\\n{code_context}\\n\\nAssistant:\"\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    print(f\"ğŸ§  {MODEL_ID.split('/')[-1]} ëª¨ë¸ì´ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=2048, # ê²½ëŸ‰ ëª¨ë¸ì€ 2048 ì •ë„ê°€ ì•ˆì •ì \n",
    "        temperature=0.1,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # JSON íŒŒì‹± ë° ì €ì¥\n",
    "    json_str = extract_json(response)\n",
    "    \n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"âœ… JSON ìƒì„± ì„±ê³µ! -> {OUTPUT_JSON}\")\n",
    "        return data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"âŒ JSON íŒŒì‹± ì‹¤íŒ¨. AI ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        print(\"--- ì‘ë‹µ ì¼ë¶€ ---\")\n",
    "        print(response[:500])\n",
    "        return None\n",
    "\n",
    "# ì‹¤í–‰\n",
    "json_data = run_full_scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "003c43c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ³ API Call Graph Analysis Result\n",
      "========================================\n",
      "â””â”€â”€ ğŸ“‚ Category: Authentication Feature\n",
      "    â”œâ”€â”€ [POST] /auth/signup (User Signup)\n",
      "    â”‚   â”œâ”€â”€ Æ’ validateSignup - Validation Chain\n",
      "    â”‚   â”œâ”€â”€ Æ’ bcrypt.hashSync - Password Hashing\n",
      "    â”‚   â””â”€â”€ Æ’ createUser - Save to DB\n",
      "    â”‚       â””â”€â”€ Æ’ User.save() - MongoDB Insert\n",
      "    â”œâ”€â”€ [POST] /auth/login (User Login)\n",
      "    â””â”€â”€ [GET] /auth/me (Retrieve User Information)\n",
      "â””â”€â”€ ğŸ“‚ Category: Post Management Feature\n",
      "    â”œâ”€â”€ [GET] /posts (Retrieve All Posts)\n",
      "    â”œâ”€â”€ [GET] /posts/:id (Retrieve Post by ID)\n",
      "    â”œâ”€â”€ [POST] /posts (Create a New Post)\n",
      "    â”‚   â””â”€â”€ Æ’ validatePost - Request Validation\n",
      "    â”œâ”€â”€ [PUT] /posts/:id (Update a Post)\n",
      "    â”‚   â””â”€â”€ Æ’ validatePost - Request Validation\n",
      "    â””â”€â”€ [DELETE] /posts/:id (Delete a Post)\n",
      "        â””â”€â”€ Æ’ validatePost - Request Validation\n"
     ]
    }
   ],
   "source": [
    "# [Cell 5] í…ìŠ¤íŠ¸ íŠ¸ë¦¬ ë·°ì–´ (JSON êµ¬ì¡° í™•ì¸ìš©)\n",
    "\n",
    "def print_tree(node, prefix=\"\", is_last=True):\n",
    "    \"\"\"ì¬ê·€ì ìœ¼ë¡œ JSON íŠ¸ë¦¬ë¥¼ ì¶œë ¥\"\"\"\n",
    "    connector = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n",
    "    \n",
    "    # ë…¸ë“œ ì´ë¦„ ê²°ì • (function ë˜ëŠ” method+url)\n",
    "    if \"method\" in node:\n",
    "        name = f\"[{node['method']}] {node['url']} ({node.get('description', '')})\"\n",
    "    elif \"function\" in node:\n",
    "        name = f\"Æ’ {node['function']} - {node.get('description', '')}\"\n",
    "    elif \"category\" in node:\n",
    "        name = f\"ğŸ“‚ Category: {node.get('categoryName', node['category'])}\"\n",
    "    else:\n",
    "        name = \"Unknown Node\"\n",
    "\n",
    "    print(prefix + connector + name)\n",
    "    \n",
    "    # ìì‹ ë…¸ë“œ ìˆœíšŒ\n",
    "    children = node.get(\"children\", [])\n",
    "    if \"endpoints\" in node:\n",
    "        children = node[\"endpoints\"]\n",
    "        \n",
    "    count = len(children)\n",
    "    for i, child in enumerate(children):\n",
    "        new_prefix = prefix + (\"    \" if is_last else \"â”‚   \")\n",
    "        print_tree(child, new_prefix, i == count - 1)\n",
    "\n",
    "def visualize_json_structure():\n",
    "    if not os.path.exists(OUTPUT_JSON):\n",
    "        print(\"âŒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    with open(OUTPUT_JSON, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(\"\\nğŸŒ³ API Call Graph Analysis Result\\n\" + \"=\"*40)\n",
    "    if \"api\" in data:\n",
    "        for cat in data[\"api\"]:\n",
    "            print_tree(cat)\n",
    "    else:\n",
    "        print(\"âš ï¸ 'api' í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. JSON êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "visualize_json_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c60f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672ca19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e2801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86bfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea9ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734fd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe0718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
