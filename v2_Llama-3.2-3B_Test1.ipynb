{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 0] í—ˆê¹…í˜ì´ìŠ¤ ë¡œê·¸ì¸ (Llama ëª¨ë¸ ì‚¬ìš© ì‹œ í•„ìˆ˜)\n",
    "from huggingface_hub import login\n",
    "\n",
    "# ì•„ê¹Œ ë³µì‚¬í•œ í† í°ì„ ë”°ì˜´í‘œ ì•ˆì— ë„£ìœ¼ì„¸ìš”\n",
    "hf_token = \"hf_ì—¬ê¸°ì—_ë³µì‚¬í•œ_í† í°ì„_ë¶™ì—¬ë„£ìœ¼ì„¸ìš”\"\n",
    "\n",
    "print(\"ğŸ” í—ˆê¹…í˜ì´ìŠ¤ ë¡œê·¸ì¸ ì‹œë„ ì¤‘...\")\n",
    "try:\n",
    "    login(token=hf_token)\n",
    "    print(\"âœ… ë¡œê·¸ì¸ ì„±ê³µ! ì´ì œ Llama ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"í† í°ì´ ì •í™•í•œì§€, 'Read' ê¶Œí•œì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a5ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì‹¤í–‰ í™˜ê²½: CUDA\n"
     ]
    }
   ],
   "source": [
    "# [Cell 1] ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "\n",
    "# ì„¤ì •ê°’\n",
    "INPUT_FILE = \"project_full_context.txt\"\n",
    "OUTPUT_JSON = \"project_flows.json\"\n",
    "\n",
    "# GPU í™•ì¸\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸš€ ì‹¤í–‰ í™˜ê²½: {device.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf3691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Pyg\\Projects\\semi\\yuzyproject-aimodels\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘... (deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct)\n",
      "   -> 16B ëª¨ë¸ì„ 4ë¹„íŠ¸ë¡œ ì••ì¶•í•˜ì—¬ ë¡œë”©í•©ë‹ˆë‹¤. (ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤)\n",
      "âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: This modeling file requires the following packages that were not found in your environment: flash_attn. Run `pip install flash_attn`\n"
     ]
    }
   ],
   "source": [
    "# [Cell 2] Llama-3.2-3B-Instruct ë¡œë”© (4070 Ti ìµœì í™”)\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# ëª¨ë¸ ë³€ê²½: ë©”íƒ€ì˜ ìµœì‹  ê²½ëŸ‰ ëª¨ë¸ (3B)\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "print(f\"ğŸš€ ì‹¤í–‰ í™˜ê²½: {'CUDA (GPU)' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# 1. 4ë¹„íŠ¸ ì–‘ìí™” ì„¤ì • (ì†ë„ UP, ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(f\"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘... ({MODEL_ID})\")\n",
    "    \n",
    "    # í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config, # 4ë¹„íŠ¸ ì ìš©\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        attn_implementation=\"eager\" # ì—ëŸ¬ ë°©ì§€\n",
    "    )\n",
    "    \n",
    "    # íŒ¨ë”© í† í° ì„¤ì • (LlamaëŠ” pad_tokenì´ ëª…ì‹œë˜ì–´ì•¼ í•¨)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (ì¤€ë¹„ ë)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "    if \"401\" in str(e) or \"gated\" in str(e):\n",
    "        print(\"\\nğŸš¨ [í•„ë…] Llama ëª¨ë¸ì€ í—ˆê¹…í˜ì´ìŠ¤ ìŠ¹ì¸ ë° í† í° ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38adbcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê³„ì¸µí˜• ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# [Cell 3] í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € (ê³„ì¸µí˜• íŠ¸ë¦¬ êµ¬ì¡° ì „ìš©)\n",
    "\n",
    "# ìˆ˜ì •ëœ SYSTEM_PROMPT (DB ë° ë¯¸ë“¤ì›¨ì–´ ì¶”ì  ê°•í™”)\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a 'Backend Code Analyst'.\n",
    "Your task is to generate a **Precise Call Graph** based ONLY on the provided code.\n",
    "\n",
    "### CRITICAL RULES (DO NOT HALLUCINATE)\n",
    "1. **Identify Database Driver**: Check `package.json` or imports. Is it `mongoose`, `mysql2`, or `pg`?\n",
    "   - If `mongoose` is used, DO NOT output SQL queries like `SELECT *`. Use Mongoose methods like `find()`, `save()`.\n",
    "2. **Trace Middleware**: If a router has `isAuth` or `validate`, you MUST include them in `children`.\n",
    "3. **Deep Trace**: Go from Router -> Middleware -> Controller -> Service/Data -> DB Library.\n",
    "\n",
    "### JSON OUTPUT FORMAT\n",
    "{\n",
    "  \"api\": [\n",
    "    {\n",
    "      \"category\": \"auth\",\n",
    "      \"categoryName\": \"Auth Feature\",\n",
    "      \"endpoints\": [\n",
    "        {\n",
    "          \"method\": \"POST\",\n",
    "          \"url\": \"/auth/signup\",\n",
    "          \"function\": \"signup\",\n",
    "          \"file\": \"controller/auth.mjs\",\n",
    "          \"description\": \"User Signup\",\n",
    "          \"children\": [\n",
    "            {\n",
    "              \"function\": \"validateSignup\",\n",
    "              \"file\": \"router/auth.mjs\",\n",
    "              \"description\": \"Validation Chain\",\n",
    "              \"children\": []\n",
    "            },\n",
    "            {\n",
    "              \"function\": \"bcrypt.hashSync\",\n",
    "              \"file\": \"controller/auth.mjs\",\n",
    "              \"description\": \"Password Hashing\",\n",
    "              \"children\": []\n",
    "            },\n",
    "            {\n",
    "              \"function\": \"createUser\",\n",
    "              \"file\": \"data/auth.mjs\",\n",
    "              \"description\": \"Save to DB\",\n",
    "              \"children\": [\n",
    "                {\n",
    "                   \"function\": \"User.save()\",\n",
    "                   \"file\": \"mongoose\",\n",
    "                   \"description\": \"MongoDB Insert\",\n",
    "                   \"children\": []\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… ê³„ì¸µí˜• ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0acc373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ 'project_full_context.txt' ì½ëŠ” ì¤‘...\n",
      "âœ… ì™„ë²½í•œ JSON íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! -> project_flows.json\n"
     ]
    }
   ],
   "source": [
    "# [Cell 4] ì½”ë“œ ë¶„ì„ ë° JSON ìƒì„± ì‹¤í–‰ (Llama 3.2 ì „ìš©)\n",
    "\n",
    "def extract_json(text):\n",
    "    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°\n",
    "    text = re.sub(r\"^```(json)?\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "    text = re.sub(r\"```$\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "    \n",
    "    # JSON êµ¬ê°„ ì¶”ì¶œ\n",
    "    start = text.find('{')\n",
    "    end = text.rfind('}')\n",
    "    if start == -1 or end == -1: return \"{}\"\n",
    "    return text[start:end+1]\n",
    "\n",
    "def run_full_scan():\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"âŒ '{INPUT_FILE}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ“‚ '{INPUT_FILE}' ì½ëŠ” ì¤‘...\")\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        full_code = f.read()\n",
    "        \n",
    "    # Llama 3.2ëŠ” 128k ë¬¸ë§¥ì„ ì§€ì›í•˜ë¯€ë¡œ ë„‰ë„‰í•˜ê²Œ ë„£ì–´ë„ ë©ë‹ˆë‹¤.\n",
    "    code_context = full_code[:60000] \n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze this code and generate Nested JSON:\\n\\n{code_context}\"}\n",
    "    ]\n",
    "\n",
    "    # ì±„íŒ… í…œí”Œë¦¿ ì ìš©\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    print(\"ğŸ§  Llama-3.2ê°€ ì½”ë“œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)\")\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=4000,\n",
    "        temperature=0.1,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    # ê²°ê³¼ ë””ì½”ë”©\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # JSON íŒŒì‹± ë° ì €ì¥\n",
    "    json_str = extract_json(response)\n",
    "    \n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"âœ… ì™„ë²½í•œ JSON íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! -> {OUTPUT_JSON}\")\n",
    "        return data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"âŒ JSON íŒŒì‹± ì‹¤íŒ¨. AI ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        print(response[:500])\n",
    "        return None\n",
    "\n",
    "# ì‹¤í–‰\n",
    "json_data = run_full_scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c43c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ³ API Call Graph Analysis Result\n",
      "========================================\n",
      "â””â”€â”€ ğŸ“‚ Category: Auth Feature\n",
      "    â”œâ”€â”€ [POST] /auth/signup (User Signup)\n",
      "    â”‚   â”œâ”€â”€ Æ’ validateSignup - Validation Chain\n",
      "    â”‚   â”œâ”€â”€ Æ’ bcrypt.hashSync - Password Hashing\n",
      "    â”‚   â””â”€â”€ Æ’ createUser - Save to DB\n",
      "    â”‚       â””â”€â”€ Æ’ User.save() - MongoDB Insert\n",
      "    â”œâ”€â”€ [POST] /auth/login (User Login)\n",
      "    â”‚   â”œâ”€â”€ Æ’ validateLogin - Validation Chain\n",
      "    â”‚   â”œâ”€â”€ Æ’ bcrypt.compare - Password Verification\n",
      "    â”‚   â”œâ”€â”€ Æ’ createJwtToken - Create JWT Token\n",
      "    â”‚   â””â”€â”€ Æ’ res.status(200).json({ token, userid }) - Send JWT Token and User ID\n",
      "    â””â”€â”€ [GET] /auth/me (Get Current User Info)\n",
      "        â”œâ”€â”€ Æ’ authRepository.findById(req.id) - Find User by ID\n",
      "        â””â”€â”€ Æ’ res.status(200).json({ token, userid }) - Send JWT Token and User ID\n"
     ]
    }
   ],
   "source": [
    "# [Cell 5] í…ìŠ¤íŠ¸ íŠ¸ë¦¬ ë·°ì–´ (JSON êµ¬ì¡° í™•ì¸ìš©)\n",
    "\n",
    "def print_tree(node, prefix=\"\", is_last=True):\n",
    "    \"\"\"ì¬ê·€ì ìœ¼ë¡œ JSON íŠ¸ë¦¬ë¥¼ ì¶œë ¥\"\"\"\n",
    "    connector = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n",
    "    \n",
    "    # ë…¸ë“œ ì´ë¦„ ê²°ì • (function ë˜ëŠ” method+url)\n",
    "    if \"method\" in node:\n",
    "        name = f\"[{node['method']}] {node['url']} ({node.get('description', '')})\"\n",
    "    elif \"function\" in node:\n",
    "        name = f\"Æ’ {node['function']} - {node.get('description', '')}\"\n",
    "    elif \"category\" in node:\n",
    "        name = f\"ğŸ“‚ Category: {node.get('categoryName', node['category'])}\"\n",
    "    else:\n",
    "        name = \"Unknown Node\"\n",
    "\n",
    "    print(prefix + connector + name)\n",
    "    \n",
    "    # ìì‹ ë…¸ë“œ ìˆœíšŒ\n",
    "    children = node.get(\"children\", [])\n",
    "    if \"endpoints\" in node:\n",
    "        children = node[\"endpoints\"]\n",
    "        \n",
    "    count = len(children)\n",
    "    for i, child in enumerate(children):\n",
    "        new_prefix = prefix + (\"    \" if is_last else \"â”‚   \")\n",
    "        print_tree(child, new_prefix, i == count - 1)\n",
    "\n",
    "def visualize_json_structure():\n",
    "    if not os.path.exists(OUTPUT_JSON):\n",
    "        print(\"âŒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    with open(OUTPUT_JSON, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(\"\\nğŸŒ³ API Call Graph Analysis Result\\n\" + \"=\"*40)\n",
    "    if \"api\" in data:\n",
    "        for cat in data[\"api\"]:\n",
    "            print_tree(cat)\n",
    "    else:\n",
    "        print(\"âš ï¸ 'api' í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. JSON êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "visualize_json_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c60f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672ca19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e2801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86bfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea9ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734fd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe0718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
