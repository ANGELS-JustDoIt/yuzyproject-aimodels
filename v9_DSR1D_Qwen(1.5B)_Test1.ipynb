{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì‹¤í–‰ í™˜ê²½: CUDA\n"
     ]
    }
   ],
   "source": [
    "# [Cell 1] ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# ì„¤ì •ê°’\n",
    "INPUT_FILE = \"project_full_context.txt\"\n",
    "OUTPUT_JSON = \"project_flows.json\"\n",
    "\n",
    "# GPU í™•ì¸\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸš€ ì‹¤í–‰ í™˜ê²½: {device.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf3691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì‹¤í–‰ í™˜ê²½: CUDA (GPU)\n",
      "ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘... (Qwen/Qwen2.5-Coder-1.5B-Instruct)\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# [Cell 2] DeepSeek-R1-Distill-Qwen-1.5B ë¡œë”© (ì´ˆê³ ì† ì¶”ë¡ )\n",
    "\n",
    "# â˜… ëª¨ë¸ ë³€ê²½: 2025ë…„í˜• ì´ˆì†Œí˜• ì¶”ë¡  ëª¨ë¸ (1.5B)\n",
    "MODEL_ID = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "print(f\"ğŸš€ ì‹¤í–‰ í™˜ê²½: {'CUDA (GPU)' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# 1.5BëŠ” ë„ˆë¬´ ì‘ì•„ì„œ 4ë¹„íŠ¸ ì•ˆ í•´ë„ ë˜ì§€ë§Œ, ë” ë¹ ë¥¸ ì†ë„ë¥¼ ìœ„í•´ ì ìš©\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(f\"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘... ({MODEL_ID})\")\n",
    "    print(\"   -> 1.5B ëª¨ë¸ì´ë¼ ë‹¤ìš´ë¡œë“œë„ ê¸ˆë°© ëë‚©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        attn_implementation=\"eager\"\n",
    "    )\n",
    "    \n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (ì¤€ë¹„ ë)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38adbcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê³„ì¸µí˜• ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# [Cell 3] í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € (ê³„ì¸µí˜• íŠ¸ë¦¬ êµ¬ì¡° ì „ìš©)\n",
    "\n",
    "# ìˆ˜ì •ëœ SYSTEM_PROMPT (DB ë° ë¯¸ë“¤ì›¨ì–´ ì¶”ì  ê°•í™”)\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a 'Backend Code Analyst'.\n",
    "Your task is to generate a **Precise Call Graph** based ONLY on the provided code.\n",
    "\n",
    "### CRITICAL RULES (DO NOT HALLUCINATE)\n",
    "1. **Identify Database Driver**: Check `package.json` or imports. Is it `mongoose`, `mysql2`, or `pg`?\n",
    "   - If `mongoose` is used, DO NOT output SQL queries like `SELECT *`. Use Mongoose methods like `find()`, `save()`.\n",
    "2. **Trace Middleware**: If a router has `isAuth` or `validate`, you MUST include them in `children`.\n",
    "3. **Deep Trace**: Go from Router -> Middleware -> Controller -> Service/Data -> DB Library.\n",
    "\n",
    "### JSON OUTPUT FORMAT\n",
    "{\n",
    "  \"api\": [\n",
    "    {\n",
    "      \"category\": \"auth\",\n",
    "      \"categoryName\": \"Auth Feature\",\n",
    "      \"endpoints\": [\n",
    "        {\n",
    "          \"method\": \"POST\",\n",
    "          \"url\": \"/auth/signup\",\n",
    "          \"function\": \"signup\",\n",
    "          \"file\": \"controller/auth.mjs\",\n",
    "          \"description\": \"User Signup\",\n",
    "          \"children\": [\n",
    "            {\n",
    "              \"function\": \"validateSignup\",\n",
    "              \"file\": \"router/auth.mjs\",\n",
    "              \"description\": \"Validation Chain\",\n",
    "              \"children\": []\n",
    "            },\n",
    "            {\n",
    "              \"function\": \"bcrypt.hashSync\",\n",
    "              \"file\": \"controller/auth.mjs\",\n",
    "              \"description\": \"Password Hashing\",\n",
    "              \"children\": []\n",
    "            },\n",
    "            {\n",
    "              \"function\": \"createUser\",\n",
    "              \"file\": \"data/auth.mjs\",\n",
    "              \"description\": \"Save to DB\",\n",
    "              \"children\": [\n",
    "                {\n",
    "                   \"function\": \"User.save()\",\n",
    "                   \"file\": \"mongoose\",\n",
    "                   \"description\": \"MongoDB Insert\",\n",
    "                   \"children\": []\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… ê³„ì¸µí˜• ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0acc373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ 'project_full_context.txt' ì½ëŠ” ì¤‘...\n",
      "âœ… ì™„ë²½í•œ JSON íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! -> project_flows.json\n"
     ]
    }
   ],
   "source": [
    "# [Cell 4] ì½”ë“œ ë¶„ì„ ë° JSON ìƒì„± (R1 1.5B ì „ìš©)\n",
    "\n",
    "def extract_json(text):\n",
    "    # <think> íƒœê·¸ ì œê±° (ìƒê° ê³¼ì •ì€ JSONì— ë„£ì§€ ì•ŠìŒ)\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
    "    text = re.sub(r\"^```(json)?\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"```$\", \"\", text, flags=re.MULTILINE)\n",
    "    start = text.find('{')\n",
    "    end = text.rfind('}')\n",
    "    if start == -1 or end == -1: return \"{}\"\n",
    "    return text[start:end+1]\n",
    "\n",
    "def run_full_scan():\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"âŒ '{INPUT_FILE}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ“‚ '{INPUT_FILE}' ì½ëŠ” ì¤‘...\")\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        full_code = f.read()\n",
    "        \n",
    "    code_context = full_code[:30000] # 1.5BëŠ” ë¬¸ë§¥ì„ ë„ˆë¬´ ê¸¸ê²Œ ì£¼ë©´ í˜ë“¤ì–´í•¨\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze this code structure deeply and return the JSON.\\n\\nCode:\\n{code_context}\"}\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    print(\"ğŸ§  Tiny R1ì´ ì¶”ë¡  ì¤‘ì…ë‹ˆë‹¤... (ì†ë„: ğŸš€)\")\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=2048,\n",
    "        temperature=0.6,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # ê²°ê³¼ í™•ì¸ (ìƒê° ê³¼ì •ì´ ê¶ê¸ˆí•˜ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ)\n",
    "    print(response) \n",
    "    \n",
    "    json_str = extract_json(response)\n",
    "    \n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"âœ… JSON ìƒì„± ì„±ê³µ! -> {OUTPUT_JSON}\")\n",
    "        return data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"âŒ JSON íŒŒì‹± ì‹¤íŒ¨. AI ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        print(response[:500])\n",
    "        return None\n",
    "\n",
    "# ì‹¤í–‰\n",
    "json_data = run_full_scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c43c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ³ API Call Graph Analysis Result\n",
      "========================================\n",
      "â””â”€â”€ ğŸ“‚ Category: Auth Feature\n",
      "    â”œâ”€â”€ [POST] /auth/signup (User Signup)\n",
      "    â”‚   â”œâ”€â”€ Æ’ validateSignup - Validation Chain\n",
      "    â”‚   â”œâ”€â”€ Æ’ bcrypt.hashSync - Password Hashing\n",
      "    â”‚   â””â”€â”€ Æ’ createUser - Save to DB\n",
      "    â”‚       â””â”€â”€ Æ’ User.save() - MongoDB Insert\n",
      "    â”œâ”€â”€ [POST] /auth/login (User Login)\n",
      "    â”‚   â”œâ”€â”€ Æ’ validateLogin - Validation Chain\n",
      "    â”‚   â”œâ”€â”€ Æ’ bcrypt.compare - Password Verification\n",
      "    â”‚   â”œâ”€â”€ Æ’ createJwtToken - Create JWT Token\n",
      "    â”‚   â””â”€â”€ Æ’ res.status(200).json({ token, userid }) - Send JWT Token and User ID\n",
      "    â””â”€â”€ [GET] /auth/me (Get Current User Info)\n",
      "        â”œâ”€â”€ Æ’ authRepository.findById(req.id) - Find User by ID\n",
      "        â””â”€â”€ Æ’ res.status(200).json({ token, userid }) - Send JWT Token and User ID\n"
     ]
    }
   ],
   "source": [
    "# [Cell 5] í…ìŠ¤íŠ¸ íŠ¸ë¦¬ ë·°ì–´ (JSON êµ¬ì¡° í™•ì¸ìš©)\n",
    "\n",
    "def print_tree(node, prefix=\"\", is_last=True):\n",
    "    \"\"\"ì¬ê·€ì ìœ¼ë¡œ JSON íŠ¸ë¦¬ë¥¼ ì¶œë ¥\"\"\"\n",
    "    connector = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n",
    "    \n",
    "    # ë…¸ë“œ ì´ë¦„ ê²°ì • (function ë˜ëŠ” method+url)\n",
    "    if \"method\" in node:\n",
    "        name = f\"[{node['method']}] {node['url']} ({node.get('description', '')})\"\n",
    "    elif \"function\" in node:\n",
    "        name = f\"Æ’ {node['function']} - {node.get('description', '')}\"\n",
    "    elif \"category\" in node:\n",
    "        name = f\"ğŸ“‚ Category: {node.get('categoryName', node['category'])}\"\n",
    "    else:\n",
    "        name = \"Unknown Node\"\n",
    "\n",
    "    print(prefix + connector + name)\n",
    "    \n",
    "    # ìì‹ ë…¸ë“œ ìˆœíšŒ\n",
    "    children = node.get(\"children\", [])\n",
    "    if \"endpoints\" in node:\n",
    "        children = node[\"endpoints\"]\n",
    "        \n",
    "    count = len(children)\n",
    "    for i, child in enumerate(children):\n",
    "        new_prefix = prefix + (\"    \" if is_last else \"â”‚   \")\n",
    "        print_tree(child, new_prefix, i == count - 1)\n",
    "\n",
    "def visualize_json_structure():\n",
    "    if not os.path.exists(OUTPUT_JSON):\n",
    "        print(\"âŒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    with open(OUTPUT_JSON, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(\"\\nğŸŒ³ API Call Graph Analysis Result\\n\" + \"=\"*40)\n",
    "    if \"api\" in data:\n",
    "        for cat in data[\"api\"]:\n",
    "            print_tree(cat)\n",
    "    else:\n",
    "        print(\"âš ï¸ 'api' í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. JSON êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "visualize_json_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c60f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672ca19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e2801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86bfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea9ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734fd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe0718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
